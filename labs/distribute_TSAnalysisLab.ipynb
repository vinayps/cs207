{
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3", 
      "name": "python3", 
      "language": "python"
    }, 
    "language_info": {
      "mimetype": "text/x-python", 
      "nbconvert_exporter": "python", 
      "name": "python", 
      "file_extension": ".py", 
      "version": "3.5.1", 
      "pygments_lexer": "ipython3", 
      "codemirror_mode": {
        "version": 3, 
        "name": "ipython"
      }
    }
  }, 
  "nbformat": 4, 
  "nbformat_minor": 0, 
  "cells": [
    {
      "execution_count": 13, 
      "cell_type": "code", 
      "source": [
        "%matplotlib inline\n", 
        "import numpy as np\n", 
        "import matplotlib.pyplot as plt\n", 
        "import numpy.fft as nfft"
      ], 
      "outputs": [], 
      "metadata": {
        "collapsed": true
      }
    }, 
    {
      "execution_count": 14, 
      "cell_type": "code", 
      "source": [
        "d16=np.genfromtxt('169975.dat_folded')\n", 
        "d51=np.genfromtxt('51886.dat_folded')\n", 
        "plt.plot(d16[:,0], d16[:,1])\n", 
        "plt.plot(d51[:,0], d51[:,1])"
      ], 
      "outputs": [], 
      "metadata": {
        "collapsed": false
      }
    }, 
    {
      "execution_count": 16, 
      "cell_type": "code", 
      "source": [
        "from scipy.interpolate import interp1d\n", 
        "x1 = np.linspace(0.01,0.99, 1024)\n", 
        "c51=interp1d(d51[:,0], d51[:,1])(x1)\n", 
        "c16=interp1d(d16[:,0], d16[:,1])(x1)\n", 
        "plt.plot(x1, c16)\n", 
        "plt.plot(x1, c51)"
      ], 
      "outputs": [], 
      "metadata": {
        "collapsed": false
      }
    }, 
    {
      "source": [
        "## Q1. Computing Cross-Correlation\n", 
        "\n", 
        "We provide here a standardization function"
      ], 
      "cell_type": "markdown", 
      "metadata": {}
    }, 
    {
      "execution_count": 4, 
      "cell_type": "code", 
      "source": [
        "def stand(x):\n", 
        "    return (x-np.mean(x))/np.std(x, ddof=0)"
      ], 
      "outputs": [], 
      "metadata": {
        "collapsed": true
      }
    }, 
    {
      "source": [
        "Write a function that takes two time seroes and uses the fourier method to calculate a cross-correlation function"
      ], 
      "cell_type": "markdown", 
      "metadata": {}
    }, 
    {
      "execution_count": 8, 
      "cell_type": "code", 
      "source": [
        "def ccor(ts1, ts2):\n", 
        "    #your code here\n"
      ], 
      "outputs": [], 
      "metadata": {
        "collapsed": true
      }
    }, 
    {
      "source": [
        "We plot the correlation function. Where does it maximize?"
      ], 
      "cell_type": "markdown", 
      "metadata": {}
    }, 
    {
      "execution_count": 9, 
      "cell_type": "code", 
      "source": [
        "plt.plot(x1, ccor(stand(c51), stand(c16)))"
      ], 
      "outputs": [], 
      "metadata": {
        "collapsed": false
      }
    }, 
    {
      "source": [
        "## Q2. Dimensionality reduction with SAX\n", 
        "\n", 
        "The idea behind SAX is to reduce dinensionality by capturing pieces of the curve and getting an average. So you are replacing the function by a set of steps. The next part is to encode the steps using some technique, here we will use binary strings. The [iSAX paper](https://www.google.com/url?sa=t&rct=j&q=&esrc=s&source=web&cd=1&ved=0ahUKEwi2y4u9p__LAhUD9R4KHYslCuAQFggdMAA&url=http%3A%2F%2Fwww.cs.ucr.edu%2F~eamonn%2FiSAX.pdf&usg=AFQjCNEhDE8xHlXBVfSkLUBo4UsVRHOyTw&sig2=dgG-oNiR2MAYcqyUWzCs3Q), which you should skim, at the very least, is the source of this explanation below\n", 
        "\n", 
        "![](https://dl.dropboxusercontent.com/u/75194/saxrepr.png)\n", 
        "\n"
      ], 
      "cell_type": "markdown", 
      "metadata": {}
    }, 
    {
      "source": [
        "Our interpolated curves have 1024 points. Bin them in chunks of 32, so we have $w=32$ chunks, and use a cardinality $a=4$ to get a SAX(T, 32, 4). Represent both light curves this way. For bonus points solve it for a general cardinality a (you'll have to get the gaussian deivision from the table above).\n", 
        "\n", 
        "Remember you are doing this on standardized time series. You can assume that the series has been interpolated to a power of 2 length. Write a function to do this below:"
      ], 
      "cell_type": "markdown", 
      "metadata": {}
    }, 
    {
      "execution_count": 73, 
      "cell_type": "code", 
      "source": [
        "def representer4(series, w): # a will be 4\n", 
        "    #your code here\n"
      ], 
      "outputs": [], 
      "metadata": {
        "collapsed": true
      }
    }, 
    {
      "source": [
        "We apply the function"
      ], 
      "cell_type": "markdown", 
      "metadata": {}
    }, 
    {
      "execution_count": 74, 
      "cell_type": "code", 
      "source": [
        "representer4(stand(c51), 32)"
      ], 
      "outputs": [], 
      "metadata": {
        "collapsed": false
      }
    }, 
    {
      "execution_count": 75, 
      "cell_type": "code", 
      "source": [
        "representer4(stand(c16), 32)"
      ], 
      "outputs": [], 
      "metadata": {
        "collapsed": false
      }
    }, 
    {
      "source": [
        "## Q3. VPTree (to read, not to submit)\n", 
        "\n", 
        "Read the VPTree implementation is modified from https://github.com/huyng/algorithms/tree/master/vptree. Also see http://stevehanov.ca/blog/index.php?id=130 for a good explanation of the concepts (and C++ code if you are so inclined). You will use the VPtree to store some distances next week in an index so it is imperative that you read atleast one implementation.\n", 
        "\n"
      ], 
      "cell_type": "markdown", 
      "metadata": {}
    }
  ]
}