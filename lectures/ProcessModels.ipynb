{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process Models in the Database and Elsewhere\n",
    "\n",
    "Code examples here taken from the Python Cookbook, freely available at http://chimera.labs.oreilly.com/books/1230000000393/index.html. This is an excellent book and will help you with your python programming and with your project.\n",
    "\n",
    "I saw the characterization of database systems along the lines we have talked about in this course first in http://db.cs.berkeley.edu/papers/fntdb07-architecture.pdf . This is an incredible review paper, if a little bit dated. But I stongly recommend you read it now: you will get a lot out of it. Between this paper, \"Designing Database Intensive Applications, and what you have learnt, you will be able to read all modern database papers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need concurrency for a multitude of reasons. You are writing a multi-user database: it must take more than one request at a time.\n",
    "\n",
    "You must plan how to handle these requests. Lets talk in terms of a **unit of execution**, something used to handle one user, or do one transaction. Then the question arises: what do these map to?\n",
    "\n",
    "- an operating system process (multiprocessing). Scheduled by OS kernel, state maintained in private, per-process address space and execution context. Really slow switching.\n",
    "- an operating system thread (multithreading). Scheduled by OS, but does not have its own address space and context; shares it with other threads within the same process. Fast switching\n",
    "- an inside-process thread (light weight thread or coroutine) with asynchronous IO: one process, so the adress and context are shared with the other \"user\" threads or coroutines. Any long running IO can block the process, so must be done asynchronously and perhaps in another OS thread. Super fast switching.\n",
    "\n",
    "We have seen all three of thse choices, the last one ad nauseum. We'll focus a bit more on the first two today, but hopefully you have seen more about them in cs205 or other courses as well...\n",
    "\n",
    "We'll call the unit-of-execution in the case of a DBMS, the DBMS Worker. In general, this will map onto 1 client request, or one transaction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process per DBMS worker model\n",
    "\n",
    "This really is two models: spawn a process every thime a new request comes in, or use a process pool from which a process is chosen to handle the request. Once the request is done, the process goes back to the pool.\n",
    "\n",
    "This is easy to implement, and many databases were first started when OS based thread support was poor. Thus they used this model.\n",
    "\n",
    "The complication here is sharing memory structures, especially for the lock table and bufer pool(this is a memory pool into which database pages are mapped to use: these must be flushed to disk on transactions but also serve as a cache for gets). This uses POSIX shared memory or System V ipc (see http://semanchuk.com/philip/sysv_ipc/)\n",
    "\n",
    "Also note that memory-mapping can be used for this purpose. Memory maps map part of a file to memory, and let you address the filea s if you were addressing a memory buffer. They take care of bring in parts of the file to memory under the hood. This implementation is used in lmdb and boltdb to provide fast transactions.\n",
    "\n",
    "(Note that OS's also provide buffer caches in which they load existing files in memory. But this is not shareable, and many databases prefer to manage this mapping themselves)\n",
    "\n",
    "Because of the overhead of context-switching, process per dbms worker models tend to be not very scaleable. But in Python, with the GIL, it might be a preferred model if there is any substantial CPU bound processing like a stored procedure. Still, ine could run a Threadpool, with the ability to use a process as a coprocessor. See http://chimera.labs.oreilly.com/books/1230000000393/ch12.html#_dealing_with_the_gil_and_how_to_stop_worrying_about_it .\n",
    "\n",
    "The buffer pool is stored in shared memory thats shared by all these processes. Its important to use shared memory. You might be tempted to create the database process in the memory of the main process, and after fork write to it in the children. This is a bad idea as memory semantics for children are copy on write, so that you will be then writing to the new processes memory space and thus database replica, and not to the main database.\n",
    "\n",
    "Process per worker model is supported by IBM DB2, PostgreSQL, and Oracle."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Worker per thread or threadpool model\n",
    "\n",
    "Here the main thread listens for the database connections, and each connection is then allocated a new thread. This is a mdel thats really simple to start of with, but has issues with deadlocks and stuff: you must be careful. Although, these challenges are also present in the multiprocess model due to use of ahared memory and thus the need to lock there.\n",
    "\n",
    "The thread per worker model scales well to many concurrent connections (as long as you dont have the GIL, and even then, if the computation part is small: although note that if you had an overall faster speed by using an in memory db and thus minimizing IO, most of your remaining overhead would be in the GIL unless you used C code/Cython to access the memory and do some computations on it.) IBM DB2 has a worker per thread model, as do MS SQL server, MySQL, Informix, and Sybase.\n",
    "\n",
    "In this case, the buffer pool is simply a heap resident data structure. where as in the process based model, it is allocated in shared memory so that it is available to all processes)\n",
    "\n",
    "When a thread or process needs a page to be read from disk it will generate an io request (read-into) with the disk address and the memory address. By doing stuff in fixed size pages (where the size is oprimized for cache and the size of your data) makes this process fast.\n",
    "\n",
    "The reverse is dont to write (write from). The lock table uses a similar implementation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Light weight threads or coroutines\n",
    "\n",
    "In the past, when OS thread support was not so good, and now again since the resurgence of interest in asynchronous programming, many widely used databases implement their own light-weight threads. To quote the stonebraker paper:\n",
    "\n",
    "> These lightweight threads, or DBMS threads, replace the role of the OS threads described in the previous section. Each DBMS thread is programmed to manage its own state, to perform all potentially block- ing operations (e.g., I/Os) via non-blocking, asynchronous interfaces, and to frequently yield control to a scheduling routine that dispatches among these tasks. \n",
    "\n",
    "Sybase and Informix are examples of this mode of usage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Threads\n",
    "\n",
    "To avoid the potential for deadlock, programs that use locks should be written in a way such that each thread is only allowed to acquire one lock at a time.\n",
    "\n",
    "Here is a locked dictionary, a proxy for a database if you like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import threading\n",
    "class LockableDict: \n",
    "    def __init__(self):\n",
    "        self._d={}\n",
    "        self._dlock={}\n",
    "        \n",
    "    def __getitem__(self, attr):\n",
    "        return self._d[attr]\n",
    "    \n",
    "    def __setitem__(self, attr, val):\n",
    "        if attr not in self._d:\n",
    "            self._dlock[attr]=threading.Lock()\n",
    "        with self._dlock[attr]:\n",
    "            self._d[attr] = val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l = LockableDict()\n",
    "l['a'] = 3\n",
    "l['a']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the usual echo server written with a thread pool from the `concurrent.futures` package. We saw some other ways of writing this server in the sockets class using the `socketserver` module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting threads0.py\n"
     ]
    }
   ],
   "source": [
    "%%file threads0.py\n",
    "from socket import AF_INET, SOCK_STREAM, socket \n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "def echo_client(sock, client_addr):\n",
    "    print('Got connection from', client_addr) \n",
    "    while True:\n",
    "        msg = sock.recv(65536) \n",
    "        if not msg:\n",
    "            break\n",
    "        sock.sendall(msg) \n",
    "    print('Client closed connection') \n",
    "    sock.close()\n",
    "    \n",
    "def echo_server(addr):\n",
    "    pool = ThreadPoolExecutor(12) \n",
    "    sock = socket(AF_INET, SOCK_STREAM) \n",
    "    sock.bind(addr)\n",
    "    sock.listen(5)\n",
    "    while True:\n",
    "        client_sock, client_addr = sock.accept()\n",
    "        pool.submit(echo_client, client_sock, client_addr)\n",
    "        \n",
    "echo_server(('',15000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And here is something more along the lines of what we did last time in setting up a thread pool, but you can see how the pool is set up and fed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing threads1.py\n"
     ]
    }
   ],
   "source": [
    "%%file threads1.py\n",
    "from socket import socket, AF_INET, SOCK_STREAM \n",
    "from threading import Thread\n",
    "from queue import Queue\n",
    "\n",
    "def echo_client(q):\n",
    "    sock, client_addr = q.get()\n",
    "    print('Got connection from', client_addr) \n",
    "    while True:\n",
    "        msg = sock.recv(65536) \n",
    "        if not msg:\n",
    "            break\n",
    "        sock.sendall(msg) \n",
    "    print('Client closed connection')\n",
    "    sock.close()\n",
    "\n",
    "def echo_server(addr, nworkers): \n",
    "    # Launch the client workers \n",
    "    q = Queue()\n",
    "    for n in range(nworkers):\n",
    "        t = Thread(target=echo_client, args=(q,))\n",
    "        t.daemon = True\n",
    "        t.start()\n",
    "    # Run the server\n",
    "    sock = socket(AF_INET, SOCK_STREAM) sock.bind(addr)\n",
    "    sock.listen(5)\n",
    "    while True:\n",
    "        client_sock, client_addr = sock.accept()\n",
    "        q.put((client_sock, client_addr))\n",
    "    \n",
    "echo_server(('',15000), 128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So lets use this model to write a simple, in-memory database server."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting dbserver.py\n"
     ]
    }
   ],
   "source": [
    "%%file dbserver.py\n",
    "from socket import AF_INET, SOCK_STREAM, socket, SOL_SOCKET, SO_REUSEADDR\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import threading\n",
    "class LockableDict: \n",
    "    def __init__(self):\n",
    "        self._d={}\n",
    "        self._dlock={}\n",
    "        \n",
    "    def __getitem__(self, attr):\n",
    "        return self._d[attr]\n",
    "    \n",
    "    def __setitem__(self, attr, val):\n",
    "        if attr not in self._d:\n",
    "            self._dlock[attr]=threading.Lock()\n",
    "        print(\"LOCKING FOR\", attr, val)\n",
    "        with self._dlock[attr]:\n",
    "            self._d[attr] = val\n",
    "        print(\"UNLOCKED FOR\", attr, val)\n",
    "            \n",
    "def db_client(sock, client_addr, ldict):\n",
    "    print('Got connection from', client_addr) \n",
    "    while True:\n",
    "        msg = sock.recv(65536)\n",
    "        print(\"msg\", msg)\n",
    "        if not msg:\n",
    "            break\n",
    "        key, value = msg.decode().split('=')\n",
    "        print(\"k,v\", key, value)\n",
    "        ldict[key] = value\n",
    "        sock.sendall(value.encode())\n",
    "    print('Client closed connection') \n",
    "    sock.close()\n",
    "    \n",
    "def db_server(addr):\n",
    "    print(\"creating lockable dict and pool\")\n",
    "    ldict=LockableDict()\n",
    "    pool = ThreadPoolExecutor(50) \n",
    "    sock = socket(AF_INET, SOCK_STREAM)\n",
    "    sock.setsockopt(SOL_SOCKET, SO_REUSEADDR, 1)\n",
    "    sock.bind(addr)\n",
    "    sock.listen(15)\n",
    "    while True:\n",
    "        print('connection')\n",
    "        client_sock, client_addr = sock.accept()\n",
    "        pool.submit(db_client, client_sock, client_addr, ldict)\n",
    "        \n",
    "db_server(('',15000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's a client that uses a threadpool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting dbclient.py\n"
     ]
    }
   ],
   "source": [
    "%%file dbclient.py\n",
    "import sys\n",
    "from socket import socket, AF_INET, SOCK_STREAM\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "def fetch(i):\n",
    "    s = socket(AF_INET, SOCK_STREAM)\n",
    "    s.connect(('localhost', 15000))\n",
    "    print(\"sending, i\",i)\n",
    "    s.send(\"a={}\".format(i).encode())\n",
    "    print(\"sent\")\n",
    "    return s.recv(65536)\n",
    "pool = ThreadPoolExecutor(20)\n",
    "thrs=[]\n",
    "for i in range(40):\n",
    "    t = pool.submit(fetch, i)\n",
    "    thrs.append(t)\n",
    "for i in range(40):\n",
    "    print('i', i, thrs[i].result())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And another that uses a processpool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting dbclient2.py\n"
     ]
    }
   ],
   "source": [
    "%%file dbclient2.py\n",
    "import sys\n",
    "from socket import socket, AF_INET, SOCK_STREAM\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "def fetch(i):\n",
    "    s = socket(AF_INET, SOCK_STREAM)\n",
    "    s.connect(('localhost', 15000))\n",
    "    print(\"sending, i\",i)\n",
    "    s.send(\"a={}\".format(i).encode())\n",
    "    print(\"sent\")\n",
    "    return s.recv(65536)\n",
    "pool = ProcessPoolExecutor(20)\n",
    "thrs=[]\n",
    "for i in range(40):\n",
    "    t = pool.submit(fetch, i)\n",
    "    thrs.append(t)\n",
    "for i in range(40):\n",
    "    print('i', i, thrs[i].result())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And a third that uses the process pool using the built in `map` method, just for illustration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing dbclient3.py\n"
     ]
    }
   ],
   "source": [
    "%%file dbclient3.py\n",
    "import sys\n",
    "from socket import socket, AF_INET, SOCK_STREAM\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "def fetch(i):\n",
    "    s = socket(AF_INET, SOCK_STREAM)\n",
    "    s.connect(('localhost', 15000))\n",
    "    print(\"sending, i\",i)\n",
    "    s.send(\"a={}\".format(i).encode())\n",
    "    print(\"sent\")\n",
    "    return s.recv(65536)\n",
    "\n",
    "with ProcessPoolExecutor(20) as pool: \n",
    "    for result in pool.map(fetch, range(40)):\n",
    "        print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of blocking, one can use callbacks. For example (from the cookbook):\n",
    "\n",
    "```python\n",
    "def when_done(r): \n",
    "    print('Got:', r.result())\n",
    "with ProcessPoolExecutor() as pool: \n",
    "        future_result = pool.submit(work, arg)\n",
    "        future_result.add_done_callback(when_done)\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We do not show how we can create a multiprocessing based db server. But its doable. Three things to keep in mind\n",
    "\n",
    "(a) you can create the database by doing a multiprocessing.lock\n",
    "(b) you must however do this in shared memory\n",
    "(c) you cannot easily pass the socket in the client function like we did above. This is as function arguments are passed from one process to the other by pickling, and sockets are not pickle-able. This leaves you with the choice of sending the data only to a child process, or using `multiprocessing.reduction` to somehow pickle the socket, or preforking (what apache does) in which the accept is run in the client (see http://foobarnbaz.com/2011/08/30/developing-scalable-services-with-python/) for an example."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Daemonization\n",
    "\n",
    "You want your process to run afteryou kill your shell. See http://chimera.labs.oreilly.com/books/1230000000393/ch12.html#_problem_210 ."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
