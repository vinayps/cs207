{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concurrency with coroutines\n",
    "\n",
    "Guido:\n",
    ">We entice you with a promise. It is possible to write asynchronous code that combines the efficiency of callbacks with the classic good looks of multithreaded programming. This combination is achieved with a pattern called \"coroutines\". Using Python 3.4's standard asyncio library, and a package called \"aiohttp\", fetching a URL in a coroutine is very direct:\n",
    "\n",
    "\n",
    "```python\n",
    "@asyncio.coroutine\n",
    "def fetch(self, url):\n",
    "    response = yield from self.session.get(url)\n",
    "    body = yield from response.read()\n",
    "```\n",
    "\n",
    "In 3.5 its even more clear:\n",
    "\n",
    "```python\n",
    "async def fetch(self, url):\n",
    "        response = await self.session.get(url)\n",
    "        body = await response.read()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remembering yield from"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import namedtuple\n",
    "Result = namedtuple('Result', 'count average')\n",
    "def averager_subgen():\n",
    "    print(\"    |sg>starting subgen\")\n",
    "    total = 0.0\n",
    "    count = 0 \n",
    "    average = None \n",
    "    while True:\n",
    "        print(\"    |sg>  average yielded out\", average)\n",
    "        term = yield average\n",
    "        print(\"    |sg>  term sent in\", term)\n",
    "        if term is None:\n",
    "            break\n",
    "        total += term\n",
    "        count += 1\n",
    "        average = total/count\n",
    "    return Result(count, average)\n",
    "\n",
    "def average_my_values_delegen_simple():\n",
    "    agen = averager_subgen()\n",
    "    print(\"  |dg>created a new averager\",id(agen))\n",
    "    overall_av = yield from agen\n",
    "    #yield from consumes all the values, like a list\n",
    "    #not an individual value\n",
    "    print(\"  |dg>now\", overall_av)\n",
    "    return overall_av\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "values_to_send=[1,2,3,4,5,6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. creating delegating generator\n",
      "2. priming till yield from by sending in None\n",
      "  |dg>created a new averager 4886813600\n",
      "    |sg>starting subgen\n",
      "    |sg>  average yielded out None\n",
      "3. in loop after first yield, None sent in\n",
      ">>sending term 1\n",
      "    |sg>  term sent in 1\n",
      "    |sg>  average yielded out 1.0\n",
      "<<getting running average 1.0\n",
      ">>sending term 2\n",
      "    |sg>  term sent in 2\n",
      "    |sg>  average yielded out 1.5\n",
      "<<getting running average 1.5\n",
      ">>sending term 3\n",
      "    |sg>  term sent in 3\n",
      "    |sg>  average yielded out 2.0\n",
      "<<getting running average 2.0\n",
      ">>sending term 4\n",
      "    |sg>  term sent in 4\n",
      "    |sg>  average yielded out 2.5\n",
      "<<getting running average 2.5\n",
      ">>sending term 5\n",
      "    |sg>  term sent in 5\n",
      "    |sg>  average yielded out 3.0\n",
      "<<getting running average 3.0\n",
      ">>sending term 6\n",
      "    |sg>  term sent in 6\n",
      "    |sg>  average yielded out 3.5\n",
      "<<getting running average 3.5\n",
      "4. Sending in None to terminate\n",
      "    |sg>  term sent in None\n",
      "  |dg>now Result(count=6, average=3.5)\n"
     ]
    },
    {
     "ename": "StopIteration",
     "evalue": "Result(count=6, average=3.5)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mStopIteration\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-b05ef8130ddf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'<<getting running average'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"4. Sending in None to terminate\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdelegating_gen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'<<getting running average'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"5. DONE\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mStopIteration\u001b[0m: Result(count=6, average=3.5)"
     ]
    }
   ],
   "source": [
    "print(\"1. creating delegating generator\")\n",
    "delegating_gen = average_my_values_delegen_simple()\n",
    "print(\"2. priming till yield from by sending in None\")\n",
    "next(delegating_gen)#priming\n",
    "print(\"3. in loop after first yield, None sent in\")\n",
    "for value in values_to_send:\n",
    "    print(\">>sending term\",value)\n",
    "    out = delegating_gen.send(value)\n",
    "    print('<<getting running average', out)\n",
    "print(\"4. Sending in None to terminate\")\n",
    "out = delegating_gen.send(None)\n",
    "print('<<getting running average', out)\n",
    "print(\"5. DONE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Back to the Future with co-routines\n",
    "\n",
    "So far, in our callbacks based example, we saw to concepts rearing their heads: the event-loop, and `select` to figure which events were fired, on-which we now call a callback. By defining the callbacks in the `Fetcher` class we were able to program with state.\n",
    "\n",
    "Now we add in some more concepts. The first one is the concept of a future which we sae earlier, the promise of a result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from selectors import DefaultSelector, EVENT_READ, EVENT_WRITE\n",
    "import socket\n",
    "selector = DefaultSelector()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The future, as you might expect is something with callbacks..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class MyFuture:\n",
    "    def __init__(self):\n",
    "        self.result = None\n",
    "        self._callbacks = []\n",
    "\n",
    "    def add_done_callback(self, fn):\n",
    "        self._callbacks.append(fn)\n",
    "\n",
    "    def set_result(self, result):\n",
    "        self.result = result\n",
    "        for fn in self._callbacks:\n",
    "            fn(self)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Fetcher:\n",
    "    \n",
    "    def __init__(self, url, host):\n",
    "        self.url = url\n",
    "        self.host = host\n",
    "        self.response = b''  # Empty array of bytes.\n",
    "\n",
    "        \n",
    "    def fetch(self):\n",
    "        global stopped\n",
    "        sock = socket.socket()\n",
    "\n",
    "        sock.setblocking(False)\n",
    "        try:\n",
    "            sock.connect((self.host, 80))\n",
    "        except BlockingIOError:\n",
    "            pass\n",
    "\n",
    "        f = MyFuture()\n",
    "\n",
    "        #resolves the future by setting a result on it\n",
    "        def on_connected():\n",
    "            print('on connected cb ran', flush=True)\n",
    "            f.set_result(None)\n",
    "        \n",
    "        \n",
    "        \n",
    "        selector.register(sock.fileno(),\n",
    "                          EVENT_WRITE,\n",
    "                          on_connected)\n",
    "        print(\"about to yield connection future\", flush=True)\n",
    "        yield f#this makes it look like fetch has returned the \"future\"\n",
    "        #bit we have not lost the state (or have to have carried it in obj)\n",
    "        #a send in will continue us here\n",
    "        print('we were connected! now back in gen', flush=True)\n",
    "        selector.unregister(sock.fileno())\n",
    "        request = 'GET {} HTTP/1.0\\r\\nHost: {}\\r\\n\\r\\n'.format(self.url, self.host)\n",
    "        sock.send(request.encode('ascii'))\n",
    "        while True:\n",
    "            print(\"in loop\")\n",
    "            #now create a new future for the data-recieving call\n",
    "            f = MyFuture()\n",
    "            def on_response():\n",
    "                chunky = sock.recv(4096)  # 4k chunk size.\n",
    "                f.set_result(chunky)\n",
    "            selector.register(sock.fileno(),\n",
    "                              EVENT_READ,\n",
    "                              on_response)\n",
    "            #now to restart the gen, we will from the main\n",
    "            #throw the data right back in\n",
    "            chunk = yield f\n",
    "            selector.unregister(sock.fileno())\n",
    "            if chunk:\n",
    "                print(\"len(chunk)\",len(chunk))\n",
    "                self.response += chunk\n",
    "            else:\n",
    "                print(\"all read\")\n",
    "                stopped= True\n",
    "                break\n",
    "\n",
    "\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need a \"main\" to yield to. This is the driver program. Notice that it wraps a co-routine. Its job is to set the coroutine up, and then provide a mechanism to send results into the co-routine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#But when the future resolves, what resumes the generator? We need a coroutine driver. Let us call it \"task\":\n",
    "#(this is our main)\n",
    "class Task:\n",
    "    def __init__(self, coro):\n",
    "        self.coro = coro\n",
    "        f = MyFuture()\n",
    "        print(\">>sending none to initial future\",f)\n",
    "        f.set_result(None)\n",
    "        print(\"...stepping\")\n",
    "        self.step(f)\n",
    "        print(\">>>after priming\")\n",
    "\n",
    "    def step(self, future):\n",
    "        try:\n",
    "            print(\"sending\", type(future.result))\n",
    "            next_future = self.coro.send(future.result)\n",
    "            print('got next future', next_future)\n",
    "\n",
    "        except StopIteration:\n",
    "            print(\"si\")\n",
    "            return None\n",
    "        next_future.add_done_callback(self.step)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The task schedules a callback on this future to call `self.step` in the Task when the future is resolved..the callback will be automatically called then."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stopped=False\n",
    "def loop():\n",
    "    while not stopped:\n",
    "        events = selector.select()\n",
    "        for event_key, event_mask in events:\n",
    "            callback = event_key.data\n",
    "            callback()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>sending none to initial future <__main__.MyFuture object at 0x10378f3c8>\n",
      "...stepping\n",
      "sending <class 'NoneType'>\n",
      "about to yield connection future\n",
      "got next future <__main__.MyFuture object at 0x10378f4e0>\n",
      ">>>after priming\n",
      "on connected cb ran\n",
      "sending <class 'NoneType'>\n",
      "we were connected! now back in gen\n",
      "in loop\n",
      "got next future <__main__.MyFuture object at 0x10378f438>\n",
      "sending <class 'bytes'>\n",
      "len(chunk) 1384\n",
      "in loop\n",
      "got next future <__main__.MyFuture object at 0x10378f4a8>\n",
      "sending <class 'bytes'>\n",
      "len(chunk) 4096\n",
      "in loop\n",
      "got next future <__main__.MyFuture object at 0x10378f518>\n",
      "sending <class 'bytes'>\n",
      "len(chunk) 56\n",
      "in loop\n",
      "got next future <__main__.MyFuture object at 0x10378f550>\n",
      "sending <class 'bytes'>\n",
      "len(chunk) 2551\n",
      "in loop\n",
      "got next future <__main__.MyFuture object at 0x10378f588>\n",
      "sending <class 'bytes'>\n",
      "all read\n",
      "si\n"
     ]
    }
   ],
   "source": [
    "fetcher = Fetcher('/353/', 'xkcd.com')\n",
    "Task(fetcher.fetch())\n",
    "stopped=False\n",
    "loop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What happened?\n",
    "\n",
    "1. In coroutine `fetch`, you yielded a future and paused. Control flow went all the way to the task, or driver object\n",
    "2. Meanwhile, in the select, the callback `on_response`, for example, `set_result` on this future, which ran the future-done callback\n",
    "3. This future-done callback, added in the `step` method of the `Task`, is the `step` method itself. Here the set result is `send` into the coroutine, where it accumulates into the response.\n",
    "4. we move until the next yield and repeat\n",
    "\n",
    "It is key that the things yielded are futures. Because in the transfer of control sense it feels like something has returned."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Refactoring using generators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#But when the future resolves, what resumes the generator? We need a coroutine driver. Let us call it \"task\":\n",
    "#(this is our main)\n",
    "class Task:\n",
    "    def __init__(self, coro):\n",
    "        self.coro = coro\n",
    "        f = MyFuture()\n",
    "        print(\">>sending none to initial future\",f)\n",
    "        f.set_result(None)\n",
    "        print(\"...stepping\")\n",
    "        self.step(f)\n",
    "        print(\">>>after priming\")\n",
    "\n",
    "    def step(self, future):\n",
    "        try:\n",
    "            print(\"sending\", type(future.result))\n",
    "            next_future = self.coro.send(future.result)\n",
    "            print('got next future', next_future)\n",
    "\n",
    "        except StopIteration:\n",
    "            print(\"si\")\n",
    "            return None\n",
    "        next_future.add_done_callback(self.step)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Task`, our driver, is unchanged. Meanwhile, below, we refactored the reading of a single chunk into a `read` coroutine. This will be our innermost coroutine..our subgen. It registers the callback and yields, then when the driver task sends the data back in, it returns the chunk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read(sock):\n",
    "    f = MyFuture()\n",
    "\n",
    "    def on_readable():\n",
    "        f.set_result(sock.recv(4096))\n",
    "\n",
    "    selector.register(sock.fileno(), EVENT_READ, on_readable)\n",
    "    chunk = yield f  # Read one chunk.\n",
    "    selector.unregister(sock.fileno())\n",
    "    return chunk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now multiple chunks are read using the `read_all` delegating coroutine. Each `yield aa` waits forpossibly multiple yields in the subgen to finish (which is not the case here). The subgen `read` returns after one read, and the chunk is set to that return value. Finally, a set of bytes is sent back. \n",
    "\n",
    "One might wonder where the concurrency is, and why we need futures at all. After all the chunks need to come in order. But using the futures lets us potentially have other `read`s for other urls going on at the same time, as we might need in a crawler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_all(sock):\n",
    "    global stopped\n",
    "    response = []\n",
    "    # Read whole response. Arranging reads like this\n",
    "    #guarantees their sequentiality\n",
    "    chunk = yield from read(sock)\n",
    "    while chunk:\n",
    "        response.append(chunk)\n",
    "        chunk = yield from read(sock)\n",
    "    stopped=True\n",
    "    return b''.join(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Guido:\n",
    ">If you squint and make the yield from statements disappear it looks like  conventional functions doing blocking I/O. But in fact, read and read_all are coroutines. Yielding from read pauses read_all until the I/O completes. While read_all is paused, asyncio's event loop does other work and awaits other I/O events; read_all is resumed with the result of read on the next loop tick once its event is ready."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Fetcher:\n",
    "    \n",
    "    def __init__(self, host, url):\n",
    "        self.url = url\n",
    "        self.host = host\n",
    "        self.response = b''  # Empty array of bytes.\n",
    "\n",
    "        \n",
    "    def fetch(self):\n",
    "        global stopped\n",
    "        sock = socket.socket()\n",
    "\n",
    "        sock.setblocking(False)\n",
    "        try:\n",
    "            sock.connect((self.host, 80))\n",
    "        except BlockingIOError:\n",
    "            pass\n",
    "\n",
    "        f = MyFuture()\n",
    "\n",
    "        def on_connected():\n",
    "            print('on connected cb ran')\n",
    "            f.set_result(None)\n",
    "        \n",
    "        \n",
    "        \n",
    "        selector.register(sock.fileno(),\n",
    "                          EVENT_WRITE,\n",
    "                          on_connected)\n",
    "        print(\"about to yield connection future\")\n",
    "        yield f\n",
    "        print('connected!')\n",
    "        selector.unregister(sock.fileno())\n",
    "        request = 'GET {} HTTP/1.0\\r\\nHost: xkcd.com\\r\\n\\r\\n'.format(self.url)\n",
    "        sock.send(request.encode('ascii'))\n",
    "        yield from read_all(sock)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above, now `fetch` acts as a delegating generator for the response part, waiting until everything is read and returned from `read_all`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>sending none to initial future <__main__.MyFuture object at 0x10379e860>\n",
      "...stepping\n",
      "sending <class 'NoneType'>\n",
      "about to yield connection future\n",
      "got next future <__main__.MyFuture object at 0x10379e128>\n",
      ">>>after priming\n",
      "on connected cb ran\n",
      "sending <class 'NoneType'>\n",
      "connected!\n",
      "got next future <__main__.MyFuture object at 0x10379e1d0>\n",
      "sending <class 'bytes'>\n",
      "got next future <__main__.MyFuture object at 0x10379e160>\n",
      "sending <class 'bytes'>\n",
      "got next future <__main__.MyFuture object at 0x10379e208>\n",
      "sending <class 'bytes'>\n",
      "si\n"
     ]
    }
   ],
   "source": [
    "fetcher = Fetcher('xkcd.com','/353/')\n",
    "Task(fetcher.fetch())\n",
    "stopped = False\n",
    "loop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](http://aosabook.org/en/500L/crawler-images/yield-from.png)\n",
    "\n",
    "There is one yield left amongst the yield froms. For consistency, this can be fixed...it also lets us change implementations under the hood.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read(sock):\n",
    "    f = MyFuture()\n",
    "\n",
    "    def on_readable():\n",
    "        f.set_result(sock.recv(4096))\n",
    "\n",
    "    selector.register(sock.fileno(), EVENT_READ, on_readable)\n",
    "    chunk = yield from f  # Read one chunk.\n",
    "    selector.unregister(sock.fileno())\n",
    "    return chunk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By making the future an iterator we can `yield from` it instead of `yield`ing it. Notice that we are careful to return the result. The `yield` transfers control flow to the task, then again the callback on the select sets the result, which sends data in which can now simply be retirned to the calling `yield all` using self.result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class MyFuture:\n",
    "    def __init__(self):\n",
    "        self.result = None\n",
    "        self._callbacks = []\n",
    "\n",
    "    def add_done_callback(self, fn):\n",
    "        self._callbacks.append(fn)\n",
    "\n",
    "    def set_result(self, result):\n",
    "        self.result = result\n",
    "        print(\"cblist\", self._callbacks)\n",
    "        for fn in self._callbacks:\n",
    "            fn(self)\n",
    "            \n",
    "    def __iter__(self):\n",
    "        yield self\n",
    "        return self.result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Fetcher:\n",
    "    \n",
    "    def __init__(self, host, url):\n",
    "        self.url = url\n",
    "        self.host = host\n",
    "        self.response = b''  # Empty array of bytes.\n",
    "\n",
    "        \n",
    "    def fetch(self):\n",
    "        global stopped\n",
    "        sock = socket.socket()\n",
    "\n",
    "        sock.setblocking(False)\n",
    "        try:\n",
    "            sock.connect((self.host, 80))\n",
    "        except BlockingIOError:\n",
    "            pass\n",
    "\n",
    "        f = MyFuture()\n",
    "\n",
    "        def on_connected():\n",
    "            print('on connected cb ran')\n",
    "            f.set_result(None)\n",
    "        \n",
    "        \n",
    "        \n",
    "        selector.register(sock.fileno(),\n",
    "                          EVENT_WRITE,\n",
    "                          on_connected)\n",
    "        print(\"about to yield connection future\")\n",
    "        yield from f\n",
    "        print('connected!')\n",
    "        selector.unregister(sock.fileno())\n",
    "        request = 'GET {} HTTP/1.0\\r\\nHost: xkcd.com\\r\\n\\r\\n'.format(self.url)\n",
    "        sock.send(request.encode('ascii'))\n",
    "        self.response = (yield from read_all(sock))\n",
    "        return self.response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>sending none to initial future <__main__.MyFuture object at 0x1052840b8>\n",
      "cblist []\n",
      "...stepping\n",
      "sending <class 'NoneType'>\n",
      "about to yield connection future\n",
      "got next future <__main__.MyFuture object at 0x103994400>\n",
      ">>>after priming\n",
      "on connected cb ran\n",
      "cblist [<bound method Task.step of <__main__.Task object at 0x105284128>>]\n",
      "sending <class 'NoneType'>\n",
      "connected!\n",
      "got next future <__main__.MyFuture object at 0x103994160>\n",
      "cblist [<bound method Task.step of <__main__.Task object at 0x105284128>>]\n",
      "sending <class 'bytes'>\n",
      "got next future <__main__.MyFuture object at 0x103994710>\n",
      "cblist [<bound method Task.step of <__main__.Task object at 0x105284128>>]\n",
      "sending <class 'bytes'>\n",
      "got next future <__main__.MyFuture object at 0x103994128>\n",
      "cblist [<bound method Task.step of <__main__.Task object at 0x105284128>>]\n",
      "sending <class 'bytes'>\n",
      "got next future <__main__.MyFuture object at 0x103994160>\n",
      "cblist [<bound method Task.step of <__main__.Task object at 0x105284128>>]\n",
      "sending <class 'bytes'>\n",
      "got next future <__main__.MyFuture object at 0x103994710>\n",
      "cblist [<bound method Task.step of <__main__.Task object at 0x105284128>>]\n",
      "sending <class 'bytes'>\n",
      "got next future <__main__.MyFuture object at 0x103994128>\n",
      "cblist [<bound method Task.step of <__main__.Task object at 0x105284128>>]\n",
      "sending <class 'bytes'>\n",
      "got next future <__main__.MyFuture object at 0x103994160>\n",
      "cblist [<bound method Task.step of <__main__.Task object at 0x105284128>>]\n",
      "sending <class 'bytes'>\n",
      "si\n"
     ]
    }
   ],
   "source": [
    "fetcher = Fetcher('xkcd.com', '/353/')\n",
    "Task(fetcher.fetch())\n",
    "stopped = False\n",
    "loop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets make some remarks about what we saw:\n",
    "\n",
    "- because we now chained generators using `yield from`, control flows from the innermost subgen to the outermost piece of calling code, here the event loop, after EACH iteration of the innermost subgen.\n",
    "- loops in general are more complex rather than just handling IO via callbacks. Indeed the loop maintains a `call_soon` queue. The priming, etc we see in the Task initializer can  be scheduled for the next `tick` of the loop by putting it on the queue. \n",
    "- when the future completes, the callback scheduled by the task is the one for the outermost co-routine in the coroutine chain. This callback is the one defined by the task and takes care of sending in the result\n",
    "- when the innermost subgen finishes, whatever it returns becomes the value of the enclosing yield from, which continues execution with this value. And so on until the outermost coroutine completes.\n",
    "\n",
    "`and returns the value that becomes the value of the Future that is the Task.`\n",
    "\n",
    "From http://www.bitdance.com/blog/2014/09/30_01_asycio_overview/ :\n",
    ">To summarise at a slightly higher level, the overall flow in an asyncio program is that we execute procedural style code, and every time we get to a yield from statement the execution of that procedural code is suspended. This may go on for several levels of yield from call, but eventually a Future will be yielded and make its way back up to the Task, and we will start a new pass through the EventLoop. The EventLoop will then run any call_soon callbacks. When all call_soon callbacks have run, the EventLoop uses a selector to wait for the next IO event or the next callback that was scheduled to run at a specific time. Those IO or timed events will provide values that will be set on certain Future objects, which will trigger the scheduling of call_soon callbacks which will in turn cause the corouties that were waiting for those Futures to be scheduled via call_soon to have next called on them and thus get another chance to run. This continues until all Futures are complete, including the Task or Tasks that the main EventLoop is waiting for (or the EventLoop is explicitly shut down)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Sequential downloading\n",
    "\n",
    "Server at:\n",
    "\n",
    "https://dl.dropboxusercontent.com/u/75194/fls/web.py\n",
    "\n",
    "Call as :\n",
    "\n",
    "`python -m aiohttp.web -H localhost -P 8000 fls.web:init_function`\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import time\n",
    "import sys\n",
    "def get_url(url):\n",
    "    response = requests.get(url)\n",
    "    print(\"1\", url)\n",
    "    return response.content\n",
    "\n",
    "def get_many(urls):\n",
    "    cdict={}\n",
    "    for url in urls:\n",
    "        cdict[url] = get_url(url)\n",
    "    return cdict\n",
    "        \n",
    "def download(download_func, urls):\n",
    "    start = time.time()\n",
    "    cdict = download_func(urls)\n",
    "    elapsed = time.time() - start\n",
    "    print(\"{} in {} secs\".format(len(cdict), elapsed))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trial_urls=['http://localhost:8000/{}'.format(n) for n in range(50)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 http://localhost:8000/0\n",
      "1 http://localhost:8000/1\n",
      "1 http://localhost:8000/2\n",
      "1 http://localhost:8000/3\n",
      "1 http://localhost:8000/4\n",
      "1 http://localhost:8000/5\n",
      "1 http://localhost:8000/6\n",
      "1 http://localhost:8000/7\n",
      "1 http://localhost:8000/8\n",
      "1 http://localhost:8000/9\n",
      "1 http://localhost:8000/10\n",
      "1 http://localhost:8000/11\n",
      "1 http://localhost:8000/12\n",
      "1 http://localhost:8000/13\n",
      "1 http://localhost:8000/14\n",
      "1 http://localhost:8000/15\n",
      "1 http://localhost:8000/16\n",
      "1 http://localhost:8000/17\n",
      "1 http://localhost:8000/18\n",
      "1 http://localhost:8000/19\n",
      "1 http://localhost:8000/20\n",
      "1 http://localhost:8000/21\n",
      "1 http://localhost:8000/22\n",
      "1 http://localhost:8000/23\n",
      "1 http://localhost:8000/24\n",
      "1 http://localhost:8000/25\n",
      "1 http://localhost:8000/26\n",
      "1 http://localhost:8000/27\n",
      "1 http://localhost:8000/28\n",
      "1 http://localhost:8000/29\n",
      "1 http://localhost:8000/30\n",
      "1 http://localhost:8000/31\n",
      "1 http://localhost:8000/32\n",
      "1 http://localhost:8000/33\n",
      "1 http://localhost:8000/34\n",
      "1 http://localhost:8000/35\n",
      "1 http://localhost:8000/36\n",
      "1 http://localhost:8000/37\n",
      "1 http://localhost:8000/38\n",
      "1 http://localhost:8000/39\n",
      "1 http://localhost:8000/40\n",
      "1 http://localhost:8000/41\n",
      "1 http://localhost:8000/42\n",
      "1 http://localhost:8000/43\n",
      "1 http://localhost:8000/44\n",
      "1 http://localhost:8000/45\n",
      "1 http://localhost:8000/46\n",
      "1 http://localhost:8000/47\n",
      "1 http://localhost:8000/48\n",
      "1 http://localhost:8000/49\n",
      "50 in 2.6973490715026855 secs\n"
     ]
    }
   ],
   "source": [
    "download(get_many, trial_urls)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sequential using async tech\n",
    "\n",
    "Here we use the `aiohttp` library (`pip install aiohttp`). Note that the multiple `yield from`s in `get_many_async` will sequentialize so this is not a true async program.\n",
    "\n",
    "But it illustrates a key thing about async programming. Write the code as if you were writing a blocking program and then stick in `yield from`s.\n",
    "\n",
    "The critical thing different from our illustrative effort above is the event loop from asyncio. This event loop will handle selecting on IO as well as timers, the scheduling of co-routines, and many other things. The `loop.run_until_complete()` function blocks until the top level coroutine, here `get_many async` completes. So this sets up the entire flow we were talking about earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 http://localhost:8000/0\n",
      "1 http://localhost:8000/1\n",
      "1 http://localhost:8000/2\n",
      "1 http://localhost:8000/3\n",
      "1 http://localhost:8000/4\n",
      "1 http://localhost:8000/5\n",
      "1 http://localhost:8000/6\n",
      "1 http://localhost:8000/7\n",
      "1 http://localhost:8000/8\n",
      "1 http://localhost:8000/9\n",
      "1 http://localhost:8000/10\n",
      "1 http://localhost:8000/11\n",
      "1 http://localhost:8000/12\n",
      "1 http://localhost:8000/13\n",
      "1 http://localhost:8000/14\n",
      "1 http://localhost:8000/15\n",
      "1 http://localhost:8000/16\n",
      "1 http://localhost:8000/17\n",
      "1 http://localhost:8000/18\n",
      "1 http://localhost:8000/19\n",
      "1 http://localhost:8000/20\n",
      "1 http://localhost:8000/21\n",
      "1 http://localhost:8000/22\n",
      "1 http://localhost:8000/23\n",
      "1 http://localhost:8000/24\n",
      "1 http://localhost:8000/25\n",
      "1 http://localhost:8000/26\n",
      "1 http://localhost:8000/27\n",
      "1 http://localhost:8000/28\n",
      "1 http://localhost:8000/29\n",
      "1 http://localhost:8000/30\n",
      "1 http://localhost:8000/31\n",
      "1 http://localhost:8000/32\n",
      "1 http://localhost:8000/33\n",
      "1 http://localhost:8000/34\n",
      "1 http://localhost:8000/35\n",
      "1 http://localhost:8000/36\n",
      "1 http://localhost:8000/37\n",
      "1 http://localhost:8000/38\n",
      "1 http://localhost:8000/39\n",
      "1 http://localhost:8000/40\n",
      "1 http://localhost:8000/41\n",
      "1 http://localhost:8000/42\n",
      "1 http://localhost:8000/43\n",
      "1 http://localhost:8000/44\n",
      "1 http://localhost:8000/45\n",
      "1 http://localhost:8000/46\n",
      "1 http://localhost:8000/47\n",
      "1 http://localhost:8000/48\n",
      "1 http://localhost:8000/49\n",
      "50 in 1.4821479320526123 secs\n"
     ]
    }
   ],
   "source": [
    "import asyncio, aiohttp\n",
    "\n",
    "@asyncio.coroutine\n",
    "def get_url_async(url):\n",
    "    #async operation\n",
    "    response = yield from aiohttp.request('GET', url)\n",
    "    print(\"1\", url)\n",
    "    #reading the response is a separate async op\n",
    "    content = yield from response.read()\n",
    "    #content=\"\"\n",
    "    return content\n",
    "    \n",
    "@asyncio.coroutine\n",
    "def get_many_async(urls):\n",
    "    cdict={}\n",
    "    for url in urls:\n",
    "        #print(\"by url\", url)\n",
    "        cdict[url] = yield from get_url_async(url)\n",
    "        #print(\"ay url\", url)\n",
    "    return cdict\n",
    "        \n",
    "def download_many(urls):\n",
    "    loop = asyncio.get_event_loop()\n",
    "    coro = get_many_async(urls) \n",
    "    cdict = loop.run_until_complete(coro)\n",
    "    return cdict\n",
    "\n",
    "download(download_many, trial_urls)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Totally asynchronous\n",
    "\n",
    "All we need to do to make this synchronous looking async code from above truly async is to have all the `yield from`s in the top level coroutine replaced by futures. This is the key use of futures, they convert synchronous code into async.\n",
    "\n",
    "`asyncio.as_completed(coroutines)` converts the coroutine instances into futures and now returns them. These futures are defined by the asyncio library not our implementation above).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 http://localhost:8000/18\n",
      "1 http://localhost:8000/26\n",
      "1 http://localhost:8000/37\n",
      "1 http://localhost:8000/43\n",
      "1 http://localhost:8000/14\n",
      "1 http://localhost:8000/25\n",
      "1 http://localhost:8000/46\n",
      "1 http://localhost:8000/42\n",
      "1 http://localhost:8000/13\n",
      "1 http://localhost:8000/0\n",
      "1 http://localhost:8000/30\n",
      "1 http://localhost:8000/27\n",
      "1 http://localhost:8000/7\n",
      "1 http://localhost:8000/9\n",
      "1 http://localhost:8000/44\n",
      "1 http://localhost:8000/28\n",
      "1 http://localhost:8000/36\n",
      "1 http://localhost:8000/31\n",
      "1 http://localhost:8000/12\n",
      "1 http://localhost:8000/23\n",
      "1 http://localhost:8000/15\n",
      "1 http://localhost:8000/32\n",
      "1 http://localhost:8000/4\n",
      "1 http://localhost:8000/19\n",
      "1 http://localhost:8000/17\n",
      "1 http://localhost:8000/47\n",
      "1 http://localhost:8000/21\n",
      "1 http://localhost:8000/16\n",
      "1 http://localhost:8000/39\n",
      "1 http://localhost:8000/20\n",
      "1 http://localhost:8000/3\n",
      "1 http://localhost:8000/24\n",
      "1 http://localhost:8000/10\n",
      "1 http://localhost:8000/48\n",
      "1 http://localhost:8000/29\n",
      "1 http://localhost:8000/41\n",
      "1 http://localhost:8000/1\n",
      "1 http://localhost:8000/22\n",
      "1 http://localhost:8000/34\n",
      "1 http://localhost:8000/49\n",
      "1 http://localhost:8000/35\n",
      "1 http://localhost:8000/33\n",
      "1 http://localhost:8000/38\n",
      "1 http://localhost:8000/6\n",
      "1 http://localhost:8000/11\n",
      "1 http://localhost:8000/40\n",
      "1 http://localhost:8000/5\n",
      "1 http://localhost:8000/2\n",
      "1 http://localhost:8000/45\n",
      "1 http://localhost:8000/8\n",
      "50 in 2.0112979412078857 secs\n"
     ]
    }
   ],
   "source": [
    "import asyncio, aiohttp, time\n",
    "\n",
    "\n",
    "def download(download_func, urls):\n",
    "    start = time.time()\n",
    "    cdict = download_func(urls)\n",
    "    elapsed = time.time() - start\n",
    "    print(\"{} in {} secs\".format(len(cdict), elapsed))\n",
    "    \n",
    "@asyncio.coroutine\n",
    "def get_url_async(url):\n",
    "    #async operation\n",
    "    response = yield from aiohttp.request('GET', url)\n",
    "    print(\"1\", url)\n",
    "    #reading the response is a separate async op\n",
    "    content = yield from response.read()\n",
    "    return content\n",
    "    \n",
    "\n",
    "@asyncio.coroutine\n",
    "def get_many_async(urls):\n",
    "    todos = [get_url_async(url) for url in urls]\n",
    "    results=[]\n",
    "    for future in asyncio.as_completed(todos):\n",
    "        results.append((yield from future))\n",
    "    return results\n",
    "        \n",
    "def download_many(urls):\n",
    "    loop = asyncio.get_event_loop()\n",
    "    coro = get_many_async(urls) \n",
    "    clist = loop.run_until_complete(coro)\n",
    "    return clist\n",
    "\n",
    "download(download_many, trial_urls)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just like we yielded from futures (in adition to yielding from read_all) above, we do the same in `asyncio`. Indeed (Fluent):\n",
    "\n",
    ">Using yield from with a future automatically takes care of waiting for it to finish, without blocking the event loop—because in asyncio, yield from is used to give control back to the event loop.\n",
    "Note that using yield from with a future is the coroutine equivalent of the function‐ ality offered by add_done_callback: instead of triggering a callback, when the delayed operation is done, the event loop sets the result of the future, and the yield from expression produces a return value inside our suspended coroutine, allowing it to resume.\n",
    "\n",
    "In asyncio (and in our example) you can `yield from` either a future or a coroutine. In both cases the resolution of the future advances us past the `yield from` by performing a `send`. But who does this?\n",
    "\n",
    "In our case it was the `Task` class, and we wrapped the `fetcherinstance.fetch` coroutine in it. Indeed this is precisely what happens with asyncio. From Fluent:\n",
    "\n",
    ">In order to execute, a coroutine must be scheduled, and then it’s wrapped in an asyncio.Task. Given a coroutine, there are two main ways of obtaining a Task:\n",
    "- `asyncio.async(coro_or_future, *, loop=None)`\n",
    "This function unifies coroutines and futures: the first argument can be either one. If it’s a Future or Task, it’s returned unchanged. If it’s a coroutine, async calls loop.create_task(...) on it to create a Task.\n",
    "- `BaseEventLoop.create_task(coro)`\n",
    "This method schedules the coroutine for execution and returns an asyncio.Task object. If called on a custom subclass of BaseEventLoop, the object returned may be an instance of some other Task-compatible class provided by an external library (e.g., Tornado).\n",
    "\n",
    "Several asyncio functions accept coroutines and wrap them in asyncio.Task objects automatically, using asyncio.async internally. One example is `BaseEventLoop.run_until_complete(...)`.\n",
    "\n",
    "Turns out that a `Task` IS a `Future`. This makes sense, as its being waited on by the event loop to complete. Indeed, from the docs:\n",
    ">A task is responsible for executing a coroutine object in an event loop. If the wrapped coroutine yields from a future, the task suspends the execution of the wrapped coroutine and waits for the completition of the future. When the future is done, the execution of the wrapped coroutine restarts with the result or the exception of the future.\n",
    "\n",
    ">Event loops use cooperative scheduling: an event loop only runs one task at a time. Other tasks may run in parallel if other event loops are running in different threads. While a task waits for the completion of a future, the event loop executes a new task.\n",
    "\n",
    ">The loop.run_until_complete function accepts a future or a coroutine. If it gets a coroutine, run_until_complete wraps it into a Task, similar to what wait does. Coroutines, futures, and tasks can all be driven by yield from, and this is what run_until_complete does...\n",
    "\n",
    "Notice something interesting, something you have seen before..\n",
    "\n",
    "- A coroutine chain must be ultimately driven by a caller which is not a coroutine: in this case the event loop (asyncio has the loop do the send)\n",
    "- the innermost subgenerator must be a simple generator/yield/iterable, or in the asyncio scenario we use something like `aiohttp.request` or `asyncio.sleep`. These dont have a `yield from` in them"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Threads, for comparision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 http://localhost:8000/14\n",
      "1 http://localhost:8000/13\n",
      "1 http://localhost:8000/7\n",
      "1 http://localhost:8000/2\n",
      "1 http://localhost:8000/5\n",
      "1 http://localhost:8000/15\n",
      "1 http://localhost:8000/10\n",
      "1 http://localhost:8000/4\n",
      "1 http://localhost:8000/3\n",
      "1 http://localhost:8000/8\n",
      "1 http://localhost:8000/12\n",
      "1 http://localhost:8000/18\n",
      "1 http://localhost:8000/17\n",
      "1 http://localhost:8000/1\n",
      "1 http://localhost:8000/9\n",
      "1 http://localhost:8000/16\n",
      "1 http://localhost:8000/11\n",
      "1 http://localhost:8000/6\n",
      "1 http://localhost:8000/0\n",
      "1 http://localhost:8000/19\n",
      "1 http://localhost:8000/34\n",
      "1 http://localhost:8000/21\n",
      "1 http://localhost:8000/22\n",
      "1 http://localhost:8000/20\n",
      "1 http://localhost:8000/28\n",
      "1 http://localhost:8000/24\n",
      "1 http://localhost:8000/23\n",
      "1 http://localhost:8000/36\n",
      "1 http://localhost:8000/25\n",
      "1 http://localhost:8000/39\n",
      "1 http://localhost:8000/29\n",
      "1 http://localhost:8000/30\n",
      "1 http://localhost:8000/26\n",
      "1 http://localhost:8000/27\n",
      "1 http://localhost:8000/32\n",
      "1 http://localhost:8000/33\n",
      "1 http://localhost:8000/38\n",
      "1 http://localhost:8000/31\n",
      "1 http://localhost:8000/37\n",
      "1 http://localhost:8000/35\n",
      "1 http://localhost:8000/42\n",
      "1 http://localhost:8000/40\n",
      "1 http://localhost:8000/43\n",
      "1 http://localhost:8000/41\n",
      "1 http://localhost:8000/44\n",
      "1 http://localhost:8000/46\n",
      "1 http://localhost:8000/45\n",
      "1 http://localhost:8000/47\n",
      "1 http://localhost:8000/49\n",
      "1 http://localhost:8000/48\n",
      "50 in 3.8093490600585938 secs\n"
     ]
    }
   ],
   "source": [
    "import concurrent\n",
    "MAX_WORKERS = 20\n",
    "def get_many_threaded(urls):\n",
    "    workers = min(MAX_WORKERS, len(urls))\n",
    "    with concurrent.futures.ThreadPoolExecutor(workers) as executor:\n",
    "        res = executor.map(get_url, urls)\n",
    "    return dict(zip(urls, res))\n",
    "download(get_many_threaded, trial_urls)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why not use the threaded version. I'll quote from Fluent:\n",
    ">One final point related to threads versus coroutines: if you’ve done any nontrivial programming with threads, you know how challenging it is to reason about the pro‐ gram because the scheduler can interrupt a thread at any time. You must remember to hold locks to protect the critical sections of your program, to avoid getting inter‐ rupted in the middle of a multistep operation—which could leave data in an invalid state.\n",
    "With coroutines, everything is protected against interruption by default. You must explicitly yield to let the rest of the program run. Instead of holding locks to syn‐ chronize the operations of multiple threads, you have coroutines that are “synchron‐ ized” by definition: only one of them is running at any time. And when you want to give up control, you use yield or yield from to give control back to the scheduler. That’s why it is possible to safely cancel a coroutine: by definition, a coroutine can only be cancelled when it’s suspended at a yield point, so you can perform cleanup by handling the CancelledError exception."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### File IO and blocking calls\n",
    "\n",
    "Callbacks in js and python in the single-threaded situation work because, either at userspace or OS level, we are replying on iterrupts, threads, polling, multiprocess etc to make sure stuff gets done. But our thread does not get blocked.\n",
    "\n",
    "This is also true for co-routines will co-operatively multitask.\n",
    "\n",
    "An example os what might happen if we encounter blocking code is below, since OS's lack async fileops. In a threaded version, the file-io would release the GIL and other threads would progress. But, in our case here with coroutines, we would freeze. To avoid this, we use `run_in_executor`, which actually uses a thread-pool executor. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 http://localhost:8000/30\n",
      "1 http://localhost:8000/8\n",
      "1 http://localhost:8000/47\n",
      "1 http://localhost:8000/5\n",
      "1 http://localhost:8000/14\n",
      "1 http://localhost:8000/2\n",
      "1 http://localhost:8000/29\n",
      "1 http://localhost:8000/20\n",
      "1 http://localhost:8000/11\n",
      "1 http://localhost:8000/45\n",
      "1 http://localhost:8000/6\n",
      "1 http://localhost:8000/21\n",
      "1 http://localhost:8000/33\n",
      "1 http://localhost:8000/32\n",
      "1 http://localhost:8000/17\n",
      "1 http://localhost:8000/22\n",
      "1 http://localhost:8000/44\n",
      "1 http://localhost:8000/3\n",
      "1 http://localhost:8000/48\n",
      "1 http://localhost:8000/12\n",
      "1 http://localhost:8000/23\n",
      "1 http://localhost:8000/35\n",
      "1 http://localhost:8000/4\n",
      "1 http://localhost:8000/27\n",
      "1 http://localhost:8000/39\n",
      "1 http://localhost:8000/1\n",
      "1 http://localhost:8000/41\n",
      "1 http://localhost:8000/10\n",
      "1 http://localhost:8000/7\n",
      "1 http://localhost:8000/38\n",
      "1 http://localhost:8000/15\n",
      "1 http://localhost:8000/31\n",
      "1 http://localhost:8000/25\n",
      "1 http://localhost:8000/49\n",
      "1 http://localhost:8000/16\n",
      "1 http://localhost:8000/13\n",
      "1 http://localhost:8000/24\n",
      "1 http://localhost:8000/46\n",
      "1 http://localhost:8000/26\n",
      "1 http://localhost:8000/36\n",
      "1 http://localhost:8000/19\n",
      "1 http://localhost:8000/28\n",
      "1 http://localhost:8000/34\n",
      "1 http://localhost:8000/43\n",
      "1 http://localhost:8000/42\n",
      "1 http://localhost:8000/40\n",
      "1 http://localhost:8000/0\n",
      "1 http://localhost:8000/9\n",
      "1 http://localhost:8000/37\n",
      "1 http://localhost:8000/18\n",
      "50 in 5.622989177703857 secs\n"
     ]
    }
   ],
   "source": [
    "import asyncio, aiohttp, time\n",
    "\n",
    "\n",
    "def download(download_func, urls):\n",
    "    start = time.time()\n",
    "    cdict = download_func(urls)\n",
    "    elapsed = time.time() - start\n",
    "    print(\"{} in {} secs\".format(len(cdict), elapsed))\n",
    "    \n",
    "@asyncio.coroutine\n",
    "def get_url_async(url):\n",
    "    #async operation\n",
    "    response = yield from aiohttp.request('GET', url)\n",
    "    print(\"1\", url)\n",
    "    #reading the response is a separate async op\n",
    "    content = yield from response.read()\n",
    "    return content\n",
    "    \n",
    "import uuid\n",
    "def save_file(content):\n",
    "    fname=str(uuid.uuid4())\n",
    "    with open(\"/tmp/dload-\"+fname+'.html', 'w') as fd:\n",
    "        fd.write(str(content))\n",
    "    return fname\n",
    "\n",
    "@asyncio.coroutine\n",
    "def download_and_save_one(url):\n",
    "    c = yield from get_url_async(url)\n",
    "    loop = asyncio.get_event_loop() \n",
    "    loop.run_in_executor(None,\n",
    "                save_file, c)\n",
    "    return c\n",
    "\n",
    "    \n",
    "@asyncio.coroutine\n",
    "def get_many_async(urls):\n",
    "    todos = [download_and_save_one(url) for url in urls]\n",
    "    results=[]\n",
    "    for future in asyncio.as_completed(todos):\n",
    "        results.append((yield from future))\n",
    "    return results\n",
    "        \n",
    "def download_many(urls):\n",
    "    loop = asyncio.get_event_loop()\n",
    "    coro = get_many_async(urls) \n",
    "    clist = loop.run_until_complete(coro)\n",
    "    return clist\n",
    "\n",
    "download(download_many, trial_urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[35m569fc150184ba\u001b[m\u001b[m                                   dload-6508ca3a-3cc7-498f-923a-1bde3d3b4f4a.html\r\n",
      "\u001b[35m569fc1501cc12\u001b[m\u001b[m                                   dload-66ba2ce1-60a1-4325-9a22-9bf5ba0f5170.html\r\n",
      "\u001b[35m56d64375dbf85\u001b[m\u001b[m                                   dload-683aeb05-92bb-492a-8da6-ddf9c7694512.html\r\n",
      "\u001b[1m\u001b[36mAtom Crashes\u001b[m\u001b[m                                    dload-68566095-e704-40b6-9b76-ad850b052d89.html\r\n",
      "\u001b[33mB92A7692-2496-452C-AC4C-1DAD18694C9B_IN\u001b[m\u001b[m         dload-72bc18eb-5959-4bbf-901e-96ac99389b9c.html\r\n",
      "\u001b[33mB92A7692-2496-452C-AC4C-1DAD18694C9B_OUT\u001b[m\u001b[m        dload-74265dd9-6d8e-4ed2-8080-9dff77883403.html\r\n",
      "dload-046ac6e1-9cea-417e-b85a-8d2fd0d1c972.html dload-7f7321dd-6b60-43c7-8707-c66e428baf46.html\r\n",
      "dload-0493bd09-b591-4334-bf2e-a323387b46bb.html dload-95c36af8-8ef7-4ab4-bf27-1f49552830eb.html\r\n",
      "dload-05480f0c-e08b-4292-aabf-bbf8a7aa3fc7.html dload-98d9e181-6876-468a-ab57-e146a8e78374.html\r\n",
      "dload-09af794e-221a-4f9d-8e77-6ecaeedcd4db.html dload-99b3750f-23f0-4efe-8535-4638a8b0aca5.html\r\n",
      "dload-0f892fad-d98c-42b6-9138-1608d3bc98bd.html dload-9b48afe9-9c6a-4820-92bd-0fa29d11a31d.html\r\n",
      "dload-104ae167-5e2c-4807-b243-c25395593453.html dload-9c2c4fd5-dd39-4734-9950-7449aa03111b.html\r\n",
      "dload-1217b719-ac20-42c5-bdfb-c1a2137a9c1a.html dload-a831a7ee-8870-4733-8752-d12a6efb29f5.html\r\n",
      "dload-19099e8e-d4a7-43d5-8f7f-0d13e319a0e9.html dload-af14a651-9eb8-4b29-9d4b-559078938798.html\r\n",
      "dload-1ba64b3f-2085-497e-8b8d-3a7a242aabb6.html dload-b9ae1d0c-9e8a-4e2b-8e8a-43d681a0f3fb.html\r\n",
      "dload-234d3159-732f-45b0-b98b-212214e7cf2c.html dload-bcb4fe59-2a50-4afb-9d9a-50fb78a53140.html\r\n",
      "dload-24f1de72-ac0b-4206-9b11-b55ee97e5ce0.html dload-bf34e196-e8b6-4b16-b390-80e976f5c517.html\r\n",
      "dload-26a4663e-7ae7-4635-bf53-c3bea0ff7357.html dload-c297164e-996f-440b-a6f8-d71630df5e18.html\r\n",
      "dload-2bde4887-03b0-4149-98e4-f25ad9431d5f.html dload-c2bc88da-8266-4f0d-af02-c8d19d78585c.html\r\n",
      "dload-2c258478-8248-4309-979b-0a8bf43f2cbb.html dload-c705c719-b2d6-4c19-aaff-b7278c40b547.html\r\n",
      "dload-2db0a924-2eed-4aa3-b3d0-d45899efe1c7.html dload-d9623b32-9300-43e5-bf77-88e6159a01cf.html\r\n",
      "dload-31cf1542-7cd4-4ad2-a2ce-e3e664ee5f73.html dload-edaf1e96-e42b-42ee-aa27-d1438acb4b10.html\r\n",
      "dload-353acdc0-dbb2-45a4-9843-635d31b50037.html dload-f0d6ef41-aa13-480c-b708-217ef6a8a8d4.html\r\n",
      "dload-3d2c0bf9-0a64-4ca2-a543-dc578731d5c3.html dload-ff1f570b-9bf8-4e84-94ee-2dcfbda5556c.html\r\n",
      "dload-3d7d7c06-8297-4a91-9f20-deee5ab25971.html \u001b[1m\u001b[36mlaunch-I73gqi\u001b[m\u001b[m\r\n",
      "dload-4311868d-6a4c-4e29-b9a4-c1e9632342af.html \u001b[1m\u001b[36mlaunch-NAkmmJ\u001b[m\u001b[m\r\n",
      "dload-4917a18f-4ca3-4b1c-865f-4819470045e4.html \u001b[1m\u001b[36mlaunch-YzQTyI\u001b[m\u001b[m\r\n",
      "dload-49a7de9d-45dc-4293-89dc-fb9db8cd9db1.html \u001b[1m\u001b[36mlaunchd-157.m3nlro\u001b[m\u001b[m\r\n",
      "dload-4fab1efa-1ede-467f-a18d-552f7a58bf9c.html \u001b[1m\u001b[36mlaunchd-3256.sO9Kik\u001b[m\u001b[m\r\n",
      "dload-5889f4d1-fc47-4e90-a838-c9567ee01b01.html \u001b[1m\u001b[36mlaunchd-42570.yMUzAO\u001b[m\u001b[m\r\n",
      "dload-59c28af3-5699-4104-8404-462b5510e2e8.html \u001b[1m\u001b[36mlaunchd-827.5LXWL9\u001b[m\u001b[m\r\n",
      "dload-633487fd-d5be-41b5-886b-d8a799cfd230.html \u001b[1m\u001b[36mstupidlang\u001b[m\u001b[m\r\n"
     ]
    }
   ],
   "source": [
    "! ls /tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[35m569fc150184ba\u001b[m\u001b[m                            \u001b[1m\u001b[36mlaunch-NAkmmJ\u001b[m\u001b[m\r\n",
      "\u001b[35m569fc1501cc12\u001b[m\u001b[m                            \u001b[1m\u001b[36mlaunch-YzQTyI\u001b[m\u001b[m\r\n",
      "\u001b[35m56d64375dbf85\u001b[m\u001b[m                            \u001b[1m\u001b[36mlaunchd-157.m3nlro\u001b[m\u001b[m\r\n",
      "\u001b[1m\u001b[36mAtom Crashes\u001b[m\u001b[m                             \u001b[1m\u001b[36mlaunchd-3256.sO9Kik\u001b[m\u001b[m\r\n",
      "\u001b[33mB92A7692-2496-452C-AC4C-1DAD18694C9B_IN\u001b[m\u001b[m  \u001b[1m\u001b[36mlaunchd-42570.yMUzAO\u001b[m\u001b[m\r\n",
      "\u001b[33mB92A7692-2496-452C-AC4C-1DAD18694C9B_OUT\u001b[m\u001b[m \u001b[1m\u001b[36mlaunchd-827.5LXWL9\u001b[m\u001b[m\r\n",
      "\u001b[1m\u001b[36mlaunch-I73gqi\u001b[m\u001b[m                            \u001b[1m\u001b[36mstupidlang\u001b[m\u001b[m\r\n"
     ]
    }
   ],
   "source": [
    "!rm /tmp/dload-*.html; ls /tmp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Asyncio in 3.5\n",
    "\n",
    "Everything we have done so far continues to work. but you can use `await` instead of `yield from`, and `async def` finally provides syntax that labels coroutines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 http://localhost:8000/28\n",
      "1 http://localhost:8000/36\n",
      "1 http://localhost:8000/42\n",
      "1 http://localhost:8000/24\n",
      "1 http://localhost:8000/4\n",
      "1 http://localhost:8000/35\n",
      "1 http://localhost:8000/23\n",
      "1 http://localhost:8000/39\n",
      "1 http://localhost:8000/43\n",
      "1 http://localhost:8000/37\n",
      "1 http://localhost:8000/40\n",
      "1 http://localhost:8000/17\n",
      "1 http://localhost:8000/15\n",
      "1 http://localhost:8000/10\n",
      "1 http://localhost:8000/8\n",
      "1 http://localhost:8000/45\n",
      "1 http://localhost:8000/6\n",
      "1 http://localhost:8000/3\n",
      "1 http://localhost:8000/11\n",
      "1 http://localhost:8000/22\n",
      "1 http://localhost:8000/7\n",
      "1 http://localhost:8000/46\n",
      "1 http://localhost:8000/33\n",
      "1 http://localhost:8000/2\n",
      "1 http://localhost:8000/25\n",
      "1 http://localhost:8000/38\n",
      "1 http://localhost:8000/47\n",
      "1 http://localhost:8000/14\n",
      "1 http://localhost:8000/29\n",
      "1 http://localhost:8000/9\n",
      "1 http://localhost:8000/27\n",
      "1 http://localhost:8000/48\n",
      "1 http://localhost:8000/12\n",
      "1 http://localhost:8000/13\n",
      "1 http://localhost:8000/26\n",
      "1 http://localhost:8000/31\n",
      "1 http://localhost:8000/49\n",
      "1 http://localhost:8000/1\n",
      "1 http://localhost:8000/30\n",
      "1 http://localhost:8000/5\n",
      "1 http://localhost:8000/20\n",
      "1 http://localhost:8000/0\n",
      "1 http://localhost:8000/41\n",
      "1 http://localhost:8000/32\n",
      "1 http://localhost:8000/18\n",
      "1 http://localhost:8000/44\n",
      "1 http://localhost:8000/21\n",
      "1 http://localhost:8000/19\n",
      "1 http://localhost:8000/34\n",
      "1 http://localhost:8000/16\n",
      "50 in 5.24352502822876 secs\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import asyncio\n",
    "import collections\n",
    "from contextlib import closing\n",
    "\n",
    "import aiohttp\n",
    "from aiohttp import web\n",
    "\n",
    "\n",
    "# default set low to avoid errors from remote site, such as\n",
    "# 503 - Service Temporarily Unavailable\n",
    "DEFAULT_CONCUR_REQ = 5\n",
    "MAX_CONCUR_REQ = 1000\n",
    "\n",
    "\n",
    "class FetchError(Exception):\n",
    "    def __init__(self, country_code):\n",
    "        self.country_code = country_code\n",
    "\n",
    "\n",
    "async def get_url_async(url):\n",
    "    with closing(await aiohttp.request('GET', url)) as resp:\n",
    "        if resp.status == 200:\n",
    "            print(\"1\", url)\n",
    "            content = await resp.read()\n",
    "            return content\n",
    "        elif resp.status == 404:\n",
    "            raise web.HTTPNotFound()\n",
    "        else:\n",
    "            raise aiohttp.HttpProcessingError(\n",
    "                code=resp.status, message=resp.reason,\n",
    "                headers=resp.headers)\n",
    "\n",
    "def save_file(content):\n",
    "    fname=str(uuid.uuid4())\n",
    "    with open(\"/tmp/dload-\"+fname+'.html', 'w') as fd:\n",
    "        fd.write(str(content))\n",
    "    return fname\n",
    "\n",
    "async def download_and_save_one(url): \n",
    "    try:\n",
    "        c = await get_url_async(url)\n",
    "    except web.HTTPNotFound:  # <6>\n",
    "        status = HTTPStatus.not_found\n",
    "        msg = 'not found'\n",
    "    except Exception as exc:\n",
    "        raise FetchError() from exc\n",
    "    else:\n",
    "        loop = asyncio.get_event_loop() \n",
    "        loop.run_in_executor(None,\n",
    "                save_file, c)\n",
    "    return c\n",
    "\n",
    "async def get_many_async(urls):\n",
    "    to_do = [download_and_save_one(url) for url in urls]\n",
    "\n",
    "    to_do_iter = asyncio.as_completed(to_do)\n",
    "    results=[]\n",
    "    for future in to_do_iter:\n",
    "        try:\n",
    "            res = await future\n",
    "        except FetchError as exc:\n",
    "            status = HTTPStatus.error\n",
    "        else:\n",
    "            results.append(res)\n",
    "\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "def download_many(urls):\n",
    "    loop = asyncio.get_event_loop()\n",
    "    coro = get_many_async(urls)\n",
    "    clist = loop.run_until_complete(coro)\n",
    "    return clist\n",
    "\n",
    "download(download_many, trial_urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[35m569fc150184ba\u001b[m\u001b[m                            \u001b[1m\u001b[36mlaunch-NAkmmJ\u001b[m\u001b[m\r\n",
      "\u001b[35m569fc1501cc12\u001b[m\u001b[m                            \u001b[1m\u001b[36mlaunch-YzQTyI\u001b[m\u001b[m\r\n",
      "\u001b[35m56d64375dbf85\u001b[m\u001b[m                            \u001b[1m\u001b[36mlaunchd-157.m3nlro\u001b[m\u001b[m\r\n",
      "\u001b[1m\u001b[36mAtom Crashes\u001b[m\u001b[m                             \u001b[1m\u001b[36mlaunchd-3256.sO9Kik\u001b[m\u001b[m\r\n",
      "\u001b[33mB92A7692-2496-452C-AC4C-1DAD18694C9B_IN\u001b[m\u001b[m  \u001b[1m\u001b[36mlaunchd-42570.yMUzAO\u001b[m\u001b[m\r\n",
      "\u001b[33mB92A7692-2496-452C-AC4C-1DAD18694C9B_OUT\u001b[m\u001b[m \u001b[1m\u001b[36mlaunchd-827.5LXWL9\u001b[m\u001b[m\r\n",
      "\u001b[1m\u001b[36mlaunch-I73gqi\u001b[m\u001b[m                            \u001b[1m\u001b[36mstupidlang\u001b[m\u001b[m\r\n"
     ]
    }
   ],
   "source": [
    "!rm /tmp/dload-*.html; ls /tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
